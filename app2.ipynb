{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization libraries not available: cannot import name 'axes' from 'matplotlib' (c:\\Users\\91952\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\__init__.py)\n"
     ]
    }
   ],
   "source": [
    "# Try importing visualization libraries\n",
    "visualization_available = True\n",
    "try:\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')  # Use non-interactive backend\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "except ImportError as e:\n",
    "    print(f\"Visualization libraries not available: {e}\")\n",
    "    visualization_available = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try importing XGBoost\n",
    "xgboost_available = True\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "except ImportError as e:\n",
    "    print(f\"XGBoost not available: {e}\")\n",
    "    xgboost_available = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (1000, 14)\n",
      "\n",
      "First 5 rows:\n",
      "     ID  No_Pation Gender  AGE  Urea  Cr  HbA1c  Chol   TG  HDL  LDL  VLDL  \\\n",
      "0  502      17975      F   50   4.7  46    4.9   4.2  0.9  2.4  1.4   0.5   \n",
      "1  735      34221      M   26   4.5  62    4.9   3.7  1.4  1.1  2.1   0.6   \n",
      "2  420      47975      F   50   4.7  46    4.9   4.2  0.9  2.4  1.4   0.5   \n",
      "3  680      87656      F   50   4.7  46    4.9   4.2  0.9  2.4  1.4   0.5   \n",
      "4  504      34223      M   33   7.1  46    4.9   4.9  1.0  0.8  2.0   0.4   \n",
      "\n",
      "    BMI CLASS  \n",
      "0  24.0     N  \n",
      "1  23.0     N  \n",
      "2  24.0     N  \n",
      "3  24.0     N  \n",
      "4  21.0     N  \n",
      "\n",
      "Dataset Info:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 14 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   ID         1000 non-null   int64  \n",
      " 1   No_Pation  1000 non-null   int64  \n",
      " 2   Gender     1000 non-null   object \n",
      " 3   AGE        1000 non-null   int64  \n",
      " 4   Urea       1000 non-null   float64\n",
      " 5   Cr         1000 non-null   int64  \n",
      " 6   HbA1c      1000 non-null   float64\n",
      " 7   Chol       1000 non-null   float64\n",
      " 8   TG         1000 non-null   float64\n",
      " 9   HDL        1000 non-null   float64\n",
      " 10  LDL        1000 non-null   float64\n",
      " 11  VLDL       1000 non-null   float64\n",
      " 12  BMI        1000 non-null   float64\n",
      " 13  CLASS      1000 non-null   object \n",
      "dtypes: float64(8), int64(4), object(2)\n",
      "memory usage: 109.5+ KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the dataset\n",
    "diabetes_dataset = pd.read_csv('newDiabetes.csv')\n",
    "\n",
    "# Display basic information\n",
    "print(\"Dataset Shape:\", diabetes_dataset.shape)\n",
    "print(\"\\nFirst 5 rows:\\n\", diabetes_dataset.head())\n",
    "print(\"\\nDataset Info:\\n\")\n",
    "diabetes_dataset.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_data(df):\n",
    "    # Drop ID and No_Pation columns as they are not relevant for prediction\n",
    "    df = df.drop(['ID', 'No_Pation'], axis=1)\n",
    "    \n",
    "        # Convert Gender to numeric\n",
    "    df['Gender'] = df['Gender'].map({'M': 0, 'F': 1})\n",
    "    \n",
    "    # Handle CLASS (target variable)\n",
    "    df['CLASS'] = df['CLASS'].map({'N': 0, 'Y': 1, 'P': 2})\n",
    "    \n",
    "    # Check for any invalid values in numeric columns\n",
    "    numeric_columns = ['AGE', 'Urea', 'Cr', 'HbA1c', 'Chol', 'TG', 'HDL', 'LDL', 'VLDL', 'BMI']\n",
    "    df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    # Remove rows with any invalid values\n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed Dataset Shape: (994, 12)\n",
      "\n",
      "Class Distribution:\n",
      " 1.0    839\n",
      "0.0    102\n",
      "2.0     53\n",
      "Name: CLASS, dtype: int64\n",
      "\n",
      "Visualization not available - skipping data visualization\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing\n",
    "processed_df = preprocess_data(diabetes_dataset)\n",
    "print(\"\\nProcessed Dataset Shape:\", processed_df.shape)\n",
    "print(\"\\nClass Distribution:\\n\", processed_df['CLASS'].value_counts())\n",
    "\n",
    "# Only show visualizations if libraries are available\n",
    "if visualization_available:\n",
    "    # Let's visualize some key features\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.subplot(2, 3, 1)\n",
    "    sns.boxplot(x='CLASS', y='HbA1c', data=processed_df)\n",
    "    plt.title('HbA1c by CLASS')\n",
    "    \n",
    "    plt.subplot(2, 3, 2)\n",
    "    sns.boxplot(x='CLASS', y='Urea', data=processed_df)\n",
    "    plt.title('Urea by CLASS')\n",
    "    \n",
    "    plt.subplot(2, 3, 3)\n",
    "    sns.boxplot(x='CLASS', y='BMI', data=processed_df)\n",
    "    plt.title('BMI by CLASS')\n",
    "    \n",
    "    plt.subplot(2, 3, 4)\n",
    "    sns.boxplot(x='CLASS', y='AGE', data=processed_df)\n",
    "    plt.title('Age by CLASS')\n",
    "    \n",
    "    plt.subplot(2, 3, 5)\n",
    "    sns.boxplot(x='CLASS', y='Chol', data=processed_df)\n",
    "    plt.title('Cholesterol by CLASS')\n",
    "    \n",
    "    plt.subplot(2, 3, 6)\n",
    "    sns.boxplot(x='CLASS', y='TG', data=processed_df)\n",
    "    plt.title('Triglycerides by CLASS')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\nVisualization not available - skipping data visualization\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = processed_df.drop('CLASS', axis=1)\n",
    "y = processed_df['CLASS']\n",
    "# Only show correlations if visualization is available\n",
    "if visualization_available:\n",
    "    # Calculate feature correlations\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    corr = X.corr()\n",
    "    sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "    plt.title('Feature Correlation Matrix')\n",
    "    plt.show()\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=y)\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "# Cell 5: Model Training - Random Forest\n",
    "# Define parameter grid for Random Forest\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Random Forest classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform GridSearchCV\n",
    "rf_grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=rf_param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Random Forest model...\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      "Random Forest Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "\n",
      "Random Forest Accuracy Score: 0.9698\n",
      "\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      1.00      0.95        20\n",
      "         1.0       0.98      1.00      0.99       168\n",
      "         2.0       1.00      0.45      0.62        11\n",
      "\n",
      "    accuracy                           0.97       199\n",
      "   macro avg       0.96      0.82      0.86       199\n",
      "weighted avg       0.97      0.97      0.96       199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the Random Forest model\n",
    "print(\"\\nTraining Random Forest model...\")\n",
    "rf_grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get best Random Forest model\n",
    "rf_best_model = rf_grid_search.best_estimator_\n",
    "\n",
    "# Make predictions with Random Forest\n",
    "rf_y_pred = rf_best_model.predict(X_test_scaled)\n",
    "\n",
    "# Print Random Forest results\n",
    "print(\"\\nRandom Forest Best Parameters:\", rf_grid_search.best_params_)\n",
    "print(f\"\\nRandom Forest Accuracy Score: {accuracy_score(y_test, rf_y_pred):.4f}\")\n",
    "print(\"\\nRandom Forest Classification Report:\")\n",
    "print(classification_report(y_test, rf_y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
